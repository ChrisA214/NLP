{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"binary_classification_of_movie_reviews.ipynb","provenance":[{"file_id":"1KKzm7Fsb-JxkgcivIHtTqI080D4bcIjQ","timestamp":1637099402867}],"collapsed_sections":[],"mount_file_id":"1NKljkDS7tX3iuRXP2XsllgfAmElbvytG","authorship_tag":"ABX9TyNTktPMyWBoH8nfLJyVKxmn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"EUXbwXyWn0Sx"},"source":["1. Setup"]},{"cell_type":"code","metadata":{"id":"VhDIwuXgvha1"},"source":["### This tutorial demonstrates text classification starting from plain text files stored on disk. You'll train a binary classifier\n","### to perform sentiment analysis on an IMDB dataset. This notebook trains a sentiment analysis model to classify movie reviews as \n","### positive or negative, based on the text of the review. This is an example of binary—or two-class—classification, an important \n","### and widely applicable kind of machine learning problem. You'll use the Large Movie Review Dataset that contains the text of 50,000\n","### movie reviews from the Internet Movie Database. These are split into 25,000 reviews for training and 25,000 reviews for testing. \n","### The training and testing sets are balanced, meaning they contain an equal number of positive and negative reviews."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O2GoVE04uSCv","executionInfo":{"status":"ok","timestamp":1643130355055,"user_tz":360,"elapsed":3438,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}}},"source":["import matplotlib.pyplot as plt\n","import os #(enables operating system dependent functionality)\n","import re #(this is the regular expression module)\n","import shutil #(for high-level file and directory handling)\n","import string #(for common string operations)\n","import tensorflow as tf #(tensorflow core v 2.7)\n","\n","from tensorflow.keras import layers #(takes ina tensor and outputs a tensor)\n","from tensorflow.keras import losses #(used to compute the crossentropy loss between actual and predicted values)"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EwtrTzSevQd-","executionInfo":{"status":"ok","timestamp":1643144746642,"user_tz":360,"elapsed":125,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"fcbfecbd-a4f7-48a3-d4b8-b203e5186bac"},"source":["print(tf.__version__)"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["2.7.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"RTzP6sakn5NR"},"source":["2. Pre-process Data"]},{"cell_type":"markdown","source":["  > a) Download data from url and assign it to the variable 'dataset'"],"metadata":{"id":"V5Nsr9RzbB8e"}},{"cell_type":"code","metadata":{"id":"KwsBcODn_PLI","executionInfo":{"status":"ok","timestamp":1643144792403,"user_tz":360,"elapsed":32373,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c3187c5c-45be-4cf6-f293-e3b25eae160d"},"source":["### Let's download and extract the dataset, then explore the directory structure. Here we use the Keras method \"tf.keras.utils.get_file\" to download the dataset. The method's purpose is to:\n","### download a file from a URL if it not already in the cache. Standard arguments = tf.keras.utils.get_file(fname=None, origin=None, untar=False, md5_hash=None, file_hash=None, \n","### cache_subdir='datasets', hash_algorithm='auto', extract=False, archive_format='auto', cache_dir=None). The output is the path to the downloaded file, or \"./\" and the file itself\n","### using the supplied fname or \"aclImdb_v1\" in this case. The \"untar\" argument is deprecated in favor of extract argument, but it is a boolean, whether the file should be decompressed or not.\n","### In this case it needs to be decompressed because the source file is a \".tar.gz\" file. A \"\".tar.gz\" file is achieved by archiving files into a TAR file and then compressing\n","### it with the GNU zip utility. A tar file, often called a tarball, is a collection of files wrapped up in one single file for easy storage. Technically these are TGZ files,\n","### but nearly everyone calls both .tar and .tar.gz files simply “tar files.” Both the file path and file is assigned to the variable \"dataset\" in the command below.\n","### Note in downloading the file, the file is renamed from 'aclImdb_v1.tar.gz' to 'aclImdb_v1'. There is no sub-directory. Note: 'aclImdb_v1' is a directory with files in it.\n","### So the file is a directory. So we now have './aclImdb_v1' as the directory with the files in it.\n","\n","url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\" #(if you enter this into a browser it immediately starts downloadng a file)\n","dataset =  tf.keras.utils.get_file(\"aclImdb_v1\", url, untar=True, cache_dir='.', cache_subdir='')\n"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","84131840/84125825 [==============================] - 5s 0us/step\n","84140032/84125825 [==============================] - 5s 0us/step\n"]}]},{"cell_type":"code","source":["### The type for 'dataset' is a string. That's the first clue this isn't a normal data file but rather a path.\n","\n","type(dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uZKcaGyBf9cV","executionInfo":{"status":"ok","timestamp":1643144799036,"user_tz":360,"elapsed":165,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"953fcb5c-ee8c-4a3a-f5b2-b8eb7189ddac"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["str"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["### If we enter the variable 'dataset' we get back the file name and path './aclImdb_v1'. The below comes from the \"get file\" command which names the file, gives the source (the url in this case) and\n","### establishes the directory to put the file under. I believe it has truncated the file extension \".tar.gz\", but that it is referring to the same anyway.\n","\n","dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"XOXeR3Nig6BH","executionInfo":{"status":"ok","timestamp":1643144802283,"user_tz":360,"elapsed":137,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"cb90b1af-fcfd-4bce-f70b-b179b6659c10"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'./aclImdb_v1'"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["### Note: './' is the file path for our data. Thus if I use the os.listdir() on it, I get the following. But you cannot run the os.listdir() command on either 'dataset' or './aclImdb_v1'. Also, \n","### you don't get 'aclImdb_v1' as a file or folder. 'aclImdb_v1.tar.gz' is the compressed file. The get file command above has returned the original downloaded file, plus the others shown. \n","\n","os.listdir('./')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KGDXRLSXjcnV","executionInfo":{"status":"ok","timestamp":1643144812050,"user_tz":360,"elapsed":111,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"0083d111-54b2-4501-bafc-da49a2e40f3c"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['.config', 'drive', 'aclImdb_v1.tar.gz', 'aclImdb', 'sample_data']"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["### Note the contents of './aclImdb/' below, including test and train data. \n","\n","os.listdir('./aclImdb/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jX2O2A0LtkYN","executionInfo":{"status":"ok","timestamp":1643144819871,"user_tz":360,"elapsed":153,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"f1877e80-f95d-4e94-a1d5-343ddd5cc1aa"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['README', 'train', 'imdb.vocab', 'imdbEr.txt', 'test']"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["### The os.path.* command is a Python command. os.path.dirname(path) = return the directory name of path. If 'path' is a directory, then it returns the directory name holding that directory.\n","### Note, the path name for the variable dataset is '.'. That's because dataset is set equal to './aclImdb_v1' which is the directory/file 'aclImdb_v1' and the path \".\". So it is giving\n","### you the highest level directory name.\n","\n","os.path.dirname(dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"9HzX_OuYr84p","executionInfo":{"status":"ok","timestamp":1643144837623,"user_tz":360,"elapsed":140,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"5760a679-0cd1-4098-b0a5-67d67d8872d9"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'.'"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["os.listdir('./aclImdb/train/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a8B5-phsEOKi","executionInfo":{"status":"ok","timestamp":1643144945726,"user_tz":360,"elapsed":119,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"6a97f5b6-dc73-4e32-d620-4385d0018d92"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['urls_unsup.txt',\n"," 'pos',\n"," 'labeledBow.feat',\n"," 'urls_neg.txt',\n"," 'neg',\n"," 'urls_pos.txt',\n"," 'unsup',\n"," 'unsupBow.feat']"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"1QrElBCx8swm"},"source":["\n","\n","> b) Setup and identify folder structure & files\n","\n"]},{"cell_type":"code","source":["### os.path.join(path, *paths) = join one or more components of path and *paths, or \".\"  and 'aclImdb', intelligently. This method concatenates various path components\n","### with exactly one directory separator (‘/’) following each non-empty part except the last path component. If the last path component to be joined is empty\n","### then a directory separator (‘/’) is put at the end. If a path component represents an absolute path, then all previous components joined are discarded and\n","### joining continues from the absolute path component. In this case, the second argument, 'aclImdb' is the directory name introduced above.\n","### And it is merged intelligently with the path './' or 'dataset', which means 'aclImdb' is joined with './'  to become './aclImdb'. This is then set equal to the variable dataset_dir.\n","### I thought the two were already joined based on above, maybe this is just to be sure?\n","\n","dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')"],"metadata":{"id":"uxq6FjUucB15","executionInfo":{"status":"ok","timestamp":1643144968365,"user_tz":360,"elapsed":98,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"r-7RKRHW0ZA_","executionInfo":{"status":"ok","timestamp":1643144971458,"user_tz":360,"elapsed":161,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"9162fd49-77b8-44ae-ddcd-0af08959fc47"},"source":["### See what is in the variable 'dataset_dir'.\n","\n","dataset_dir"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'./aclImdb'"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UxPJuY5U_6KK","executionInfo":{"status":"ok","timestamp":1643144975869,"user_tz":360,"elapsed":129,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"6351f179-1a02-4b11-ea5f-800ccdaa8c44"},"source":["### The os.listdir() command = method in python used to get the list of all files and directories in the specified directory. If we don't specify any directory, then list of files\n","### and directories in the current working directory will be returned. Here we use 'dataset_dir' and this get all the files and directories in '.aclImdb/'. There are 5 including the\n","### train and test data sets. This is the same contents we saw above.\n","\n","os.listdir(dataset_dir)\n"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['README', 'train', 'imdb.vocab', 'imdbEr.txt', 'test']"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0KSi1JQ4AJke","executionInfo":{"status":"ok","timestamp":1643144983058,"user_tz":360,"elapsed":111,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"d661f308-6e18-4eb8-bfa3-e429f1907469"},"source":["### The join command below just serves to define the variable \"train_dir\" as the 'train' directory currently residing inside the 'dataset_dir' or './aclImdb/' already.\n","### The os.listdir(train_dir) command produces a list of directories inside the 'train' folder, as shown below. These are directories not files and are text names.\n","\n","train_dir = os.path.join(dataset_dir, 'train')\n","os.listdir(train_dir)"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['urls_unsup.txt',\n"," 'pos',\n"," 'labeledBow.feat',\n"," 'urls_neg.txt',\n"," 'neg',\n"," 'urls_pos.txt',\n"," 'unsup',\n"," 'unsupBow.feat']"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["### This shows us what train_dir is.\n","\n","train_dir"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"DZgYtKxL5Yv8","executionInfo":{"status":"ok","timestamp":1643145014365,"user_tz":360,"elapsed":3,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"204ae961-c6a4-471f-d812-1bd28dcce354"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'./aclImdb/train'"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vKKIEHgV50kv","executionInfo":{"status":"ok","timestamp":1643145016494,"user_tz":360,"elapsed":131,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"30f24b5e-d9ac-4ecc-e14e-c970918898d7"},"source":["### Here is how you see the first 5 files inside a particular directory.\n","\n","positive = os.path.join(train_dir, 'pos')\n","os.listdir(positive)[:5]\n"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['11422_8.txt', '2449_7.txt', '7327_10.txt', '6090_7.txt', '9167_7.txt']"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jLQXIbKXAcXy","executionInfo":{"status":"ok","timestamp":1643145033871,"user_tz":360,"elapsed":127,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"f9facc21-df72-4c15-913b-51fb97695163"},"source":["### The aclImdb/train/pos and aclImdb/train/neg directories contain many text files, each of which is a single movie review. Let's take a look at one of them.\n","### Here he is using a known text file name inside 'pos' and the join function just serves to define the 'sample_file' variable.\n","\n","sample_file = os.path.join(train_dir, 'pos/1181_9.txt')\n","with open(sample_file) as f:\n","  print(f.read())"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Rachel Griffiths writes and directs this award winning short film. A heartwarming story about coping with grief and cherishing the memory of those we've loved and lost. Although, only 15 minutes long, Griffiths manages to capture so much emotion and truth onto film in the short space of time. Bud Tingwell gives a touching performance as Will, a widower struggling to cope with his wife's death. Will is confronted by the harsh reality of loneliness and helplessness as he proceeds to take care of Ruth's pet cow, Tulip. The film displays the grief and responsibility one feels for those they have loved and lost. Good cinematography, great direction, and superbly acted. It will bring tears to all those who have lost a loved one, and survived.\n"]}]},{"cell_type":"code","source":["## Repeat the above for a second review.\n","\n","sample_file2 = os.path.join(train_dir, 'pos/11883_8.txt')\n","with open(sample_file2) as f:\n","    print(f.read())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qyhQMRiy6czQ","executionInfo":{"status":"ok","timestamp":1643145036114,"user_tz":360,"elapsed":122,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"f95d03ea-606d-421d-a586-f4f3f775c624"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["I saw this movie about a week ago and still keep thinking about it. I was very moved by this movie. I found the characters very believable and likable almost to a fault. As in real life though sometimes people disappoint, as was the case with Leo, who even though I liked his character I could not have been more disappointed when he was willing to have unprotected sex even though fully aware of his HIV status. I was also disappointed with Leo for rejecting the medicine available to him, and the awful way he treated Marcel when he decided to ship him back home on the train. I think this movie showed in a very real way why HIV numbers are up in young gay men. This is in no way meant to bash gays (I am gay) and movie very well could have been made about a young straight person who makes bad choices and seems unaware of the consequences to himself and others. The only part of the movie I couldn't understand was why the (gay friendly) family was unwilling to include Marcel in Leo's illness to the point of not allowing him to go to the funeral.<br /><br />I think the biggest message from this movie is that whether gay or straight is DO NOT HAVE UNPROTECTED SEX!\n"]}]},{"cell_type":"code","source":["## Repeat the above for a second review.\n","\n","sample_file2 = os.path.join(train_dir, 'pos/2179_8.txt')\n","with open(sample_file2) as f:\n","    print(f.read())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M-yakYDJBSdb","executionInfo":{"status":"ok","timestamp":1643145038438,"user_tz":360,"elapsed":126,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"b171f555-8657-4532-e086-e77c04a37b83"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Prix de Beauté was made on the cusp of the changeover from silence to sound, which came a little later in Europe than in Hollywood. Originally conceived as a silent, it was released with a dubbed soundtrack in France, with a French actress speaking Louise Brooks' lines, but was released as a silent in Italy and other parts of Europe. I was lucky enough to see the Cineteca di Bologna's flawless new restoration of an Italian silent print at the Tribeca Film Festival. I haven't seen the talkie version yet, but I think it's safe to assume the silent version is much more satisfying, since by all reports the dubbing is poorly done (Louise Brooks is clearly speaking English, so there's no way her lips could be matched.) Also, the film is made entirely in the silent style, with few titles and little need for dialogue. Prix de Beauté tells its story visually, with exciting, imaginative camera-work. The opening is instantly kinetic, with rapidly-cut scenes of urban life and swimmers splashing at a public beach. Throughout the film there is an emphasis on visual detail, on clothing, machinery, decoration, and symbolic images such as a caged bird, a heap of torn photographs, a diamond bracelet. This is silent film technique at its pinnacle.<br /><br />Louise Brooks, of course, is responsible for saving the film from obscurity. Seeing this makes it only more heartbreaking to reflect that this was her last starring role. Lustrously beautiful, she dominates the film with her charisma and also gives a perfectly natural yet highly charged performance. Her role here, more than in the Pabst films for which she's best known, is a woman we can fully understand and sympathize with. She plays Lucienne Garnier, a typist with a possessive fiancé, who yearns to get more out of life and secretly enters a beauty contest, with immediate success. She is then torn between the excitement of her glamorous new life and her love for the man who insists she give it all up or lose him. All of the characters are drawn with nuance. The fiancé inspires pity and is not merely a brute: he loves Lucienne, but is a limited man who can't cope with her having a life apart from him or attracting the attentions of other men. Even the \"other man\" in the story is not the simple slimeball we first take him for, though his intentions may be just as possessive as the fiancé's.<br /><br />*************************WARNING: SPOILERS BELOW***************** <br /><br />The film has many fine set pieces, including Lucienne's triumph in the \"Miss Europe\" contest, shown through the comic reactions of assorted audience members, who wind up pelting the heroine with flowers; her misery as a housewife, peeling potatoes while the pendulum of the cuckoo clock marks time behind her; a nightmarish trip to a fun-fair (in the silent version, this occurs late in the film, after her marriage) at which Lucienne, crushed among the low-lifes and depressed by her husband's macho antics, decides that she can't go on with her present existence; and especially the final scene in the projection room where she views her talkie screen test. Louise Brooks may never have looked more beautiful than she does here, with the projector's beam flickering on her alabaster profile, her shoulders swathed in white fur, her face incandescent under the black helmet of hair as she watches herself singing on screen. The double shot of her exquisite corpse and her still-living image on the screen is particularly poignant: Louise Brooks' image, like Lucienne's, remains immortal despite her frustratingly aborted film career.\n"]}]},{"cell_type":"markdown","metadata":{"id":"j3kK8N85o1WD"},"source":["> c) Establish training, validation & test data splits\n","\n"]},{"cell_type":"code","metadata":{"id":"lqAC0aPbBNhq"},"source":["### Next, you will load the data off disk and prepare it into a format suitable for training. To do so, you will use the helpful text_dataset_from_directory utility, \n","### which expects a directory structure as follows.\n","\n","### main_directory/\n","### ...class_a/\n","### ......a_text_1.txt\n","### ......a_text_2.txt\n","### ...class_b/\n","### ......b_text_1.txt\n","### ......b_text_2.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RWpNefcCBwQ8","executionInfo":{"status":"ok","timestamp":1643145052573,"user_tz":360,"elapsed":1936,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}}},"source":["### To prepare a dataset for binary classification, you will need two folders on disk, corresponding to class_a and class_b. These will be the positive and \n","### negative movie reviews, which can be found in aclImdb/train/pos and aclImdb/train/neg. As the IMDB dataset contains additional folders, you will remove \n","### them before using this utility. Note, 'shutil.rmtree()' is a python utility. shutil.rmtree() = shutil.rmtree(path, ignore_errors=False, onerror=None). It will delete\n","### an entire directory tree; path must point to a directory (but not a symbolic link to a directory). If ignore_errors is true, errors resulting from failed removals\n","### will be ignored; if false or omitted, such errors are handled by calling a handler specified by onerror or, if that is omitted, they raise an exception.\n","### 'unsup' in this case is in the train folder already.\n","\n","remove_dir = os.path.join(train_dir, 'unsup')\n","shutil.rmtree(remove_dir)\n"],"execution_count":33,"outputs":[]},{"cell_type":"code","source":["### Notice the above command removes the 'unsup' file from the './aclImdb/train' or train_dir. \n","\n","os.listdir(train_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sXvcUFq3DYfM","executionInfo":{"status":"ok","timestamp":1643145056200,"user_tz":360,"elapsed":125,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"d0c80d2e-e6b5-4e34-ca1e-4b21ad9dc769"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['urls_unsup.txt',\n"," 'pos',\n"," 'labeledBow.feat',\n"," 'urls_neg.txt',\n"," 'neg',\n"," 'urls_pos.txt',\n"," 'unsupBow.feat']"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ELpccsfxCLMy","executionInfo":{"status":"ok","timestamp":1643145070608,"user_tz":360,"elapsed":1745,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"eb266e74-319b-40e4-89b2-a8d602d80b10"},"source":["### Next, you will use the text_dataset_from_directory utility to create a labeled tf.data.Dataset for train and validation data. Training data first. tf.data is a powerful collection of tools \n","### for working with data. When running a machine learning experiment, it is a best practice to divide your dataset into three splits: train, validation, and test.\n","### The IMDB dataset has already been divided into train and test by directory name, but it lacks a validation set. Let's create a training and validation set using an 80:20 split of the training\n","### data by using the validation_split argument below for the tf.keras.utils.text_dataset_from_directory utility. The syntax is as follows: tf.keras.utils.text_dataset_from_directory(directory,\n","### labels='inferred', label_mode='int', class_names=None, batch_size=32, max_length=None, shuffle=True, seed=None, validation_split=None, subset=None, follow_links=False). There is a total of 25,000\n","### text files in the train folder. Some positive and some negative. The below command takes all 25,000 from both classes, pos and neg, shuffles them, reserves 20% for validation and returns\n","### the raw_train_ds for further use. The variable name, directory chosen, and the 'subset' argument being set equal to 'training' is how we know this is training data versus test.\n","\n","batch_size = 32\n","seed = 42\n","\n","raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n","    'aclImdb/train', \n","    batch_size=batch_size, \n","    validation_split=0.2, \n","    subset='training', \n","    seed=seed)\n"],"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 25000 files belonging to 2 classes.\n","Using 20000 files for training.\n"]}]},{"cell_type":"code","source":["### Note: the method 'tf.keras.utils.text_dataset_from_directory()' will return a <<<tf.data.Dataset>>> that yields batches of texts from the subdirectories class_a and class_b, together with labels 0 and 1\n","### (0 corresponding to class_a and 1 corresponding to class_b). Only .txt files are supported at this time. Note, by default, labels='inferred', label_mode='int' from the method's parameters. So, we're\n","### now dealing with a tf.data.Dataset orgnization of the data. If label_mode is None, it yields string tensors of shape (batch_size,), containing the contents of a batch of text files.\n","### Otherwise, it yields a tuple (texts, labels), where texts has shape (batch_size,) and labels follows the following format: if label_mode is int, the labels are an int32 tensor of shape (batch_size,).\n","### if label_mode is binary, the labels are a float32 tensor of 1s and 0s of shape (batch_size, 1). if label_mode is categorial, the labels are a float32 tensor of shape (batch_size, num_classes),\n","### representing a one-hot encoding of the class index. So in this case, the dataset is a tuple of text and labels (texts, labels)."],"metadata":{"id":"qndBG1mX8O-j"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gwW48pElElgB","executionInfo":{"status":"ok","timestamp":1643145100357,"user_tz":360,"elapsed":445,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"34b03487-a140-4db2-ff93-e641d4e7845a"},"source":["### As you can see above, there are 25,000 examples in the training folder, of which you will use 80% (or 20,000) for training. \n","### As you will see in a moment, you can train a model by passing a dataset directly to <<<model.fit>>>. If you're new to tf.data, you can also iterate over \n","### the dataset and print out a few examples as follows. NOTICE THE LABELS HAVE BEEN ADDED FOR YOU. This was done in the step above. The .take() method\n","### takes the top \"n\" examples from the object. I believe the .take() method works on tensors. The .numpy() method converts a tensors object to a numpy ndarray. Also,\n","### in the below output, the words \"Review\" and \"Label\" are added. The 'b' has to do with data formatting and is added automatically. The .take(1) is for one batch.\n","\n","for text_batch, label_batch in raw_train_ds.take(1):\n","  for i in range(3):\n","    print(\"Review\", text_batch.numpy()[i])\n","    print(\"Label\", label_batch.numpy()[i])\n"],"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Review b'\"Pandemonium\" is a horror movie spoof that comes off more stupid than funny. Believe me when I tell you, I love comedies. Especially comedy spoofs. \"Airplane\", \"The Naked Gun\" trilogy, \"Blazing Saddles\", \"High Anxiety\", and \"Spaceballs\" are some of my favorite comedies that spoof a particular genre. \"Pandemonium\" is not up there with those films. Most of the scenes in this movie had me sitting there in stunned silence because the movie wasn\\'t all that funny. There are a few laughs in the film, but when you watch a comedy, you expect to laugh a lot more than a few times and that\\'s all this film has going for it. Geez, \"Scream\" had more laughs than this film and that was more of a horror film. How bizarre is that?<br /><br />*1/2 (out of four)'\n","Label 0\n","Review b\"David Mamet is a very interesting and a very un-equal director. His first movie 'House of Games' was the one I liked best, and it set a series of films with characters whose perspective of life changes as they get into complicated situations, and so does the perspective of the viewer.<br /><br />So is 'Homicide' which from the title tries to set the mind of the viewer to the usual crime drama. The principal characters are two cops, one Jewish and one Irish who deal with a racially charged area. The murder of an old Jewish shop owner who proves to be an ancient veteran of the Israeli Independence war triggers the Jewish identity in the mind and heart of the Jewish detective.<br /><br />This is were the flaws of the film are the more obvious. The process of awakening is theatrical and hard to believe, the group of Jewish militants is operatic, and the way the detective eventually walks to the final violent confrontation is pathetic. The end of the film itself is Mamet-like smart, but disappoints from a human emotional perspective.<br /><br />Joe Mantegna and William Macy give strong performances, but the flaws of the story are too evident to be easily compensated.\"\n","Label 0\n","Review b'Great documentary about the lives of NY firefighters during the worst terrorist attack of all time.. That reason alone is why this should be a must see collectors item.. What shocked me was not only the attacks, but the\"High Fat Diet\" and physical appearance of some of these firefighters. I think a lot of Doctors would agree with me that,in the physical shape they were in, some of these firefighters would NOT of made it to the 79th floor carrying over 60 lbs of gear. Having said that i now have a greater respect for firefighters and i realize becoming a firefighter is a life altering job. The French have a history of making great documentary\\'s and that is what this is, a Great Documentary.....'\n","Label 1\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rHLpYCGgFQ9N","executionInfo":{"status":"ok","timestamp":1643145124813,"user_tz":360,"elapsed":105,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"200d0f76-dfb2-4117-97ca-b2fee9c82381"},"source":["### Notice the reviews contain raw text (with punctuation and occasional HTML tags like <br/>). You will see how to handle these in the following section.\n","### The labels are 0 or 1. To see which of these correspond to positive and negative movie reviews, you can check the 'class_names' property on the dataset.\n","\n","print(\"Label 0 corresponds to\", raw_train_ds.class_names[0])\n","print(\"Label 1 corresponds to\", raw_train_ds.class_names[1])\n"],"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Label 0 corresponds to neg\n","Label 1 corresponds to pos\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vmBbHvPopR5L","executionInfo":{"status":"ok","timestamp":1643145140952,"user_tz":360,"elapsed":1655,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"485c3cef-a468-49b8-e0ef-52cc63466eee"},"source":["### Next, you will create a validation and test dataset. You will use the remaining 5,000 reviews from the training set for validation. Note: When using the validation_split and subset\n","### arguments, make sure to either specify a random seed, or to pass shuffle=False, so that the validation and training splits have no overlap.\n","\n","raw_val_ds = tf.keras.utils.text_dataset_from_directory(\n","    'aclImdb/train', \n","    batch_size=batch_size, \n","    validation_split=0.2, \n","    subset='validation', \n","    seed=seed)\n"],"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 25000 files belonging to 2 classes.\n","Using 5000 files for validation.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"199_c9TRp61f","executionInfo":{"status":"ok","timestamp":1643145148174,"user_tz":360,"elapsed":1590,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"58d549ff-8c8e-4886-d96b-1c3e7cc8af7c"},"source":["raw_test_ds = tf.keras.utils.text_dataset_from_directory(\n","    'aclImdb/test', \n","    batch_size=batch_size)\n"],"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 25000 files belonging to 2 classes.\n"]}]},{"cell_type":"markdown","metadata":{"id":"5ipJxWNWE8CT"},"source":["\n","\n","> d) Standardize, tokenize, and vectorize data for training\n","\n"]},{"cell_type":"code","metadata":{"id":"aakmxbQ5HUI4"},"source":["### Next, you will standardize, tokenize, and vectorize the data using the helpful tf.keras.layers.TextVectorization layer. Standardization refers to preprocessing the text,\n","### typically to remove punctuation or HTML elements to simplify the dataset. Tokenization refers to splitting strings into tokens (for example, splitting a sentence into individual words,\n","### by splitting on whitespace). Vectorization refers to converting tokens into numbers so they can be fed into a neural network. All of these tasks can be accomplished with this layer.\n","### As you saw above, the reviews contain various HTML tags like <br />. These tags will not be removed by the default standardizer in the TextVectorization layer (which converts text to lowercase \n","### and strips punctuation by default, but doesn't strip HTML). You will write a custom standardization function to remove the HTML.\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bmRMsb6IFC2k"},"source":["### Note: To prevent training-testing skew (also known as training-serving skew), it is important to preprocess the data identically at train and test time. To facilitate this, the TextVectorization \n","### layer can be included directly inside your model, as shown later in this tutorial.\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2KKSU6JVFDoZ","executionInfo":{"status":"ok","timestamp":1643145159559,"user_tz":360,"elapsed":114,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}}},"source":["### This is a custom standardization function for use in this exercise. It includes making all text lowercase and pulling out some HTML code breaks ie ',br />'. \n","### regex_replace() just substitutes one value for another in a given variable. re.escape normally returns a string with all \n","### non-alphanumerics backslashed; this is useful if you want to match an arbitrary literal string that may have regular expression metacharacters in it. Example is: \n","### legal_chars = string.ascii_lowercase + string.digits + \"!#$%&'*+-.^_`|~:\"  -->  print('[%s]+' % re.escape(legal_chars))  -->  [abcdefghijklmnopqrstuvwxyz0123456789!\\#\\$%\\&'\\*\\+\\-\\.\\^_`\\|\\~:]+.\n","### Note, the command \"'[%s]' % re.escape(legal_chars)\" appears to be standard format with the exception of 'legal_chars'. So you just put this string in as what youy want to replace and all punctuation\n","### is replaced by whatever you substitute. Next, string.punctuation = !\"#$%&'()*+, -./:;<=>?@[\\]^_`{|}~. \n","\n","def custom_standardization(input_data):\n","  lowercase = tf.strings.lower(input_data)\n","  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n","  return tf.strings.regex_replace(stripped_html,\n","                                  '[%s]' % re.escape(string.punctuation),\n","                                  '')\n"],"execution_count":40,"outputs":[]},{"cell_type":"code","source":["test1 = \"This is a tests... % s to see %s how the commands *&^%$#@! work with 34% ?\"\n","test2 = tf.strings.regex_replace(test1, 'see', 'seedoo')\n","test3 = tf.strings.regex_replace(test2, '[%s]' % re.escape(string.punctuation), '')\n","print(test3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KSFDvTSHMopU","executionInfo":{"status":"ok","timestamp":1643145170632,"user_tz":360,"elapsed":149,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"9a57699a-1531-4eef-e5f9-df633797675b"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(b'This is a tests  s to seedoo s how the commands  work with 34 ', shape=(), dtype=string)\n"]}]},{"cell_type":"code","source":["legal_chars = string.ascii_lowercase + string.digits + \"!#$%&'*+-.^_`|~:\"\n","l2 = ('[%s]+' % re.escape(legal_chars))\n","print(l2) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tmI0aRIzQAnK","executionInfo":{"status":"ok","timestamp":1643145172043,"user_tz":360,"elapsed":124,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"6138979e-32d5-446c-8fb4-b882fae501a1"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["[abcdefghijklmnopqrstuvwxyz0123456789!\\#\\$%\\&'\\*\\+\\-\\.\\^_`\\|\\~:]+\n"]}]},{"cell_type":"code","metadata":{"id":"wnXqXQjC3LvD","executionInfo":{"status":"ok","timestamp":1643145175561,"user_tz":360,"elapsed":102,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}}},"source":["### Next, you will create a TextVectorization layer. You will use this layer to standardize, tokenize, and vectorize our data. You set the output_mode to \n","### int to create unique integer indices for each token. Note that you're using the default split function, and the custom standardization function you defined above.\n","### You'll also define some constants for the model, like an explicit maximum sequence_length, which will cause the layer to pad or truncate sequences to exactly sequence_length values.\n","### Note, there is nothing that the below function is being applied to here. This is just the definition of the function. Here is the default:\n","### tf.keras.layers.TextVectorization(max_tokens=None, standardize='lower_and_strip_punctuation', split='whitespace', ngrams=None, output_mode='int', output_sequence_length=None, pad_to_max_tokens=False,\n","### vocabulary=None, idf_weights=None, sparse=False, ragged=False, **kwargs)\n","\n","max_features = 10000\n","sequence_length = 250\n","\n","vectorize_layer = layers.TextVectorization(\n","    standardize=custom_standardization,\n","    max_tokens=max_features,\n","    output_mode='int',\n","    output_sequence_length=sequence_length)\n"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"16JAvT5E4y_Z","executionInfo":{"status":"ok","timestamp":1643145193057,"user_tz":360,"elapsed":7122,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}}},"source":["### In Python 3, however, the map function returns a map object which is a generator object. To do so, map() loops over the items of an input iterable (or iterables)\n","### and returns an iterator that results from applying a transformation function to every item in the original input iterable. Below, .map() is a javascript function (I think).\n","### The .js map() method creates a new array populated with the results of calling a provided function on every element in the calling array.(maybe the same?)\n","### The lambda function below takes an input (x, y) and returns x. This is how we drop the labels from the text data and now have only text.\n","### Next, you will call the adapt method to fit the state of the preprocessing layer to the dataset. Some preprocessing layers have an internal state that can be computed based\n","### on a sample of the training data. The list of stateful preprocessing layers is: TextVectorization: holds a mapping between string tokens and integer indices; StringLookup and IntegerLookup:\n","### hold a mapping between input values and integer indices; Normalization: holds the mean and standard deviation of the features. Discretization: holds information about value bucket boundaries.\n","### Crucially, these layers are non-trainable. Their state is not set during training; it must be set before training, either by initializing them from a precomputed constant,\n","### or by \"adapting\" them on data. You set the state of a preprocessing layer by exposing it to training data, via the adapt() method as shown here. I believe an index matched to\n","### tokens is created here. Below here the .get_vocabulary function shows the mapping.\n","\n","train_text = raw_train_ds.map(lambda x, y: x)\n","vectorize_layer.adapt(train_text)\n"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tJWgltzz-UAt","executionInfo":{"status":"ok","timestamp":1643061381706,"user_tz":360,"elapsed":275,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"11455fdf-1a3f-4a45-cbed-b2953f4f8d22"},"source":["type(vectorize_layer)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["keras.layers.preprocessing.text_vectorization.TextVectorization"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"gtiNUTqC-dza","executionInfo":{"status":"ok","timestamp":1643145209012,"user_tz":360,"elapsed":111,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}}},"source":["### Let's create a function to see the result of using this layer to preprocess some data.\n","\n","def vectorize_text(text, label):\n","  text = tf.expand_dims(text, -1)\n","  return vectorize_layer(text), label\n"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fL0FrmT2-8rh","executionInfo":{"status":"ok","timestamp":1643145217207,"user_tz":360,"elapsed":255,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"aedb1970-6a5d-4835-bcaf-cc63ffa19acc"},"source":["### The first step here retrieves a batch (of 32 reviews and labels) from the dataset using the 'next' and 'iter' commands. Then we grab the first review and label.\n","### The first review comes back as a tensor. The label comes back 'neg'. The vectorized review comes back as (1,250) array.\n","\n","text_batch, label_batch = next(iter(raw_train_ds))\n","first_review, first_label = text_batch[0], label_batch[0]\n","print(\"Review\", first_review)\n","print(\"Label\", raw_train_ds.class_names[first_label])\n","print(\"Vectorized review\", vectorize_text(first_review, first_label))\n"],"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Review tf.Tensor(b'Great movie - especially the music - Etta James - \"At Last\". This speaks volumes when you have finally found that special someone.', shape=(), dtype=string)\n","Label neg\n","Vectorized review (<tf.Tensor: shape=(1, 250), dtype=int64, numpy=\n","array([[  86,   17,  260,    2,  222,    1,  571,   31,  229,   11, 2418,\n","           1,   51,   22,   25,  404,  251,   12,  306,  282,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0]])>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n"]}]},{"cell_type":"code","source":["### As you can see above, each token has been replaced by an integer. You can lookup the token (string) that each integer corresponds to by calling .get_vocabulary() on the layer.\n","\n","print(\"1287 ---> \",vectorize_layer.get_vocabulary()[1287])\n","print(\" 313 ---> \",vectorize_layer.get_vocabulary()[313])\n","print('Vocabulary size: {}'.format(len(vectorize_layer.get_vocabulary())))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FWy8jPCPIddn","executionInfo":{"status":"ok","timestamp":1643145227921,"user_tz":360,"elapsed":224,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"b5634de4-daee-4706-c4a5-fde66c6d9ef2"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["1287 --->  silent\n"," 313 --->  night\n","Vocabulary size: 10000\n"]}]},{"cell_type":"code","source":["### Apply functions to all three datasets: train, validate and test. I think the .map function just maps the labels back to the tensors or arrays. And 'vectorize_text()' is the\n","### function above that applies the 'vectorize_layer' function and then maps the labels back to each vector. This data is now prepared for the model.\n","\n","train_ds = raw_train_ds.map(vectorize_text)\n","val_ds = raw_val_ds.map(vectorize_text)\n","test_ds = raw_test_ds.map(vectorize_text)\n"],"metadata":{"id":"dz8BMM_TIwfZ","executionInfo":{"status":"ok","timestamp":1643145232099,"user_tz":360,"elapsed":226,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["### This type is a subset of the tf.data.Dataset object.\n","\n","type(train_ds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ifBnydvgNavI","executionInfo":{"status":"ok","timestamp":1643145248325,"user_tz":360,"elapsed":124,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"5f7535e2-7178-40c6-9651-7ab5f765db89"},"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensorflow.python.data.ops.dataset_ops.MapDataset"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["### To view an item in this object, using an iterator is a good approach. Each iteration, as shown, is 32x250 numpy array after being converted to an numpy array.\n","### 32 is the batch size. 250 is the vector for the text review.\n","\n","iterator = train_ds.__iter__()\n","next = iterator.get_next()\n","example = next[0]\n","print(example.numpy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZoxapgJ9Nf7X","executionInfo":{"status":"ok","timestamp":1643145251075,"user_tz":360,"elapsed":260,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"19ce6fec-86ab-4b82-f0df-bc3d5b12b4fd"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["[[   1    7    4 ...    0    0    0]\n"," [1354    2   61 ...    0    0    0]\n"," [  53  147    9 ...    0    0    0]\n"," ...\n"," [   2  435    5 ...    0    0    0]\n"," [   2 3137   65 ...    0    0    0]\n"," [1518 5282 1659 ...    0    0    0]]\n"]}]},{"cell_type":"code","source":["example.numpy().shape\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TRbENqqZTL0o","executionInfo":{"status":"ok","timestamp":1643145260617,"user_tz":360,"elapsed":142,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"588648bc-a6ce-4647-d11a-830577b50f62"},"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(32, 250)"]},"metadata":{},"execution_count":51}]},{"cell_type":"markdown","source":["\n","\n","> e) Configure the dataset for performance\n","\n"],"metadata":{"id":"LP7uBMMSm0Mj"}},{"cell_type":"code","source":["### These are two important methods you should use when loading data to make sure that I/O does not become blocking. \n","### .cache() keeps data in memory after it's loaded off disk. This will ensure the dataset does not become a bottleneck while training your model. If your dataset is too large\n","### to fit into memory, you can also use this method to create a performant on-disk cache, which is more efficient to read than many small files.\n","### .prefetch() overlaps data preprocessing and model execution while training. You can learn more about both methods, as well as how to cache data to disk in the data performance guide.\n","\n","AUTOTUNE = tf.data.AUTOTUNE\n","\n","train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"],"metadata":{"id":"ZnayvtK5m82i","executionInfo":{"status":"ok","timestamp":1643145266408,"user_tz":360,"elapsed":118,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}}},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":["3. Create the Model"],"metadata":{"id":"VCpkk9LdUbLm"}},{"cell_type":"code","source":["### The Embedding layer:\n","### The Embedding layer can be understood as a lookup table that maps from integer indices (which stand for specific words) to dense vectors (their embeddings).\n","### The dimensionality (or width) of the embedding is a parameter you can experiment with to see what works well for your problem, much in the same way you would\n","### experiment with the number of neurons in a Dense layer (see above, = 16). If you pass an integer to an embedding layer, the result replaces each integer with \n","## the vector from the embedding table: result = embedding_layer(tf.constant([1, 2, 3])), result.numpy(), array([[ 0.01318491, -0.02219239,  0.024673  , -0.03208025,  0.02297195],\n","### [-0.00726584,  0.03731754, -0.01209557, -0.03887399, -0.02407478], [ 0.04477594,  0.04504738, -0.02220147, -0.03642888, -0.04688282]], dtype=float32). So each number\n","### becomes a 5 element numpy array. For text or sequence problems, the Embedding layer takes a 2D tensor of integers, of shape (samples, sequence_length), where each entry is\n","### a sequence of integers. It can embed sequences of variable lengths. You could feed into the embedding layer above batches with shapes (32, 10) (batch of 32 sequences of length 10)\n","### or (64, 15) (batch of 64 sequences of length 15). The returned tensor has one more axis than the input, the embedding vectors are aligned along the new last axis.\n","### Pass it a (2, 3) input batch and the output is (2, 3, N). For more go here: https://www.tensorflow.org/text/guide/word_embeddings."],"metadata":{"id":"t6WvQyjhihXa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Dropout layer:\n","### tf.keras.layers.Dropout(rate, noise_shape=None, seed=None, **kwargs)\n","### The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting.\n","### Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over all inputs is unchanged. Note that the Dropout layer only applies when\n","### training is set to True such that no values are dropped during inference. When using model.fit, training will be appropriately set to True automatically,\n","### and in other contexts, you can set the kwarg explicitly to True when calling the layer."],"metadata":{"id":"LvRIMsbKolEs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### GlobalAveragePooling1D():\n","### Next, a GlobalAveragePooling1D layer returns a fixed-length output vector for each example by averaging over the sequence dimension. This allows the model to \n","### handle input of variable length, in the simplest way possible. If the input is (32 x 250 x 16) and you apply this layer to the sequence dimension, you end up with\n","### an output of (32 x 16), as the 250 sequence length dimension disappears. "],"metadata":{"id":"dorGfvClp__h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Dense layer:\n","### Dense implements the operation: output = activation(dot(input, kernel) + bias) where activation is the element-wise activation function passed as the activation argument,\n","### kernel is a weights matrix created by the layer, and bias is a bias vector created by the layer (only applicable if use_bias is True). These are all attributes of Dense."],"metadata":{"id":"Fl9cPuuRqrFm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Establish the number of embedding dimensions\n","\n","embedding_dim = 16"],"metadata":{"id":"p_73FYj1UnfY","executionInfo":{"status":"ok","timestamp":1643145287735,"user_tz":360,"elapsed":134,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["### Create the model. This is a sequential model. It starts with one embedding layer (max_features+1,embedding_dim) in shape. Then it has a dropout layer. The global pooling layer\n","### is like a softmax layer I believe, reducing each data point to a zero or one. Then another dropout layer, followed by a final Dense layer.\n","### Scenarios:\n","### base case: loss=.31, accuracy=.87\n","### layers.Dense(16),: loss=.61, accuracy=.64.\n","### layers.Dropout(.3),: loss=.31, accuracy=.87\n","### epochs=6: loss=.34, accuracy=.86\n","### Add Dense(16) & add Dropout(.2): loss=.57, accuracy=.85\n","### Add Dense(16) & add Dropout(.2) & epochs=6: loss=.37, accuracy=.86\n","### Add Dense(16) & add Dropout(.2) & epochs=4: loss=.32, accuracy=.87\n","### Add Dense(16) & add Dropout(.2) & epochs=3: loss=.31, accuracy=.87\n","\n","model = tf.keras.Sequential([\n","  layers.Embedding(max_features + 1, embedding_dim),   # (32,250,16)\n","  layers.Dropout(0.2),                                 # (32,250,16)  \n","  layers.GlobalAveragePooling1D(),                     # (32, 16)\n","  layers.Dropout(0.2),                                 # (32, 16)\n","  layers.Dense(1)])                                    # (32,1)\n"],"metadata":{"id":"cxQezSEJVEJB","executionInfo":{"status":"ok","timestamp":1643147428530,"user_tz":360,"elapsed":215,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}}},"execution_count":112,"outputs":[]},{"cell_type":"code","source":["### Create a summary of the model.\n","\n","model.summary()"],"metadata":{"id":"nMSQiu1tVOMZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643147431444,"user_tz":360,"elapsed":145,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"8aee3141-2be7-4c81-ad50-394e386fc0c9"},"execution_count":113,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_12\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_11 (Embedding)    (None, None, 16)          160016    \n","                                                                 \n"," dropout_26 (Dropout)        (None, None, 16)          0         \n","                                                                 \n"," global_average_pooling1d_11  (None, 16)               0         \n","  (GlobalAveragePooling1D)                                       \n","                                                                 \n"," dropout_27 (Dropout)        (None, 16)                0         \n","                                                                 \n"," dense_16 (Dense)            (None, 1)                 17        \n","                                                                 \n","=================================================================\n","Total params: 160,033\n","Trainable params: 160,033\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["### A model needs a loss function and an optimizer for training. Since this is a binary classification problem and the model outputs a probability\n","### (a single-unit layer with a sigmoid activation), you'll use losses.BinaryCrossentropy loss function. Note: I need to revisit loss functions and optimization\n","### but not now.\n","\n","model.compile(loss=losses.BinaryCrossentropy(from_logits=True),\n","              optimizer='adam',\n","              metrics=tf.metrics.BinaryAccuracy(threshold=0.0))\n"],"metadata":{"id":"kYfdKDmxsKFm","executionInfo":{"status":"ok","timestamp":1643147434924,"user_tz":360,"elapsed":174,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}}},"execution_count":114,"outputs":[]},{"cell_type":"markdown","source":["4. Train the Model"],"metadata":{"id":"61U_hPcQvNtw"}},{"cell_type":"code","source":["### You will train the model by passing the dataset object to the fit method.\n","\n","epochs = 10\n","history = model.fit(\n","    train_ds,\n","    validation_data=val_ds,\n","    epochs=epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HAQwhPWIvish","executionInfo":{"status":"ok","timestamp":1643147491093,"user_tz":360,"elapsed":50889,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"b6ff66e5-64f9-4088-aa75-446a4384989c"},"execution_count":115,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","625/625 [==============================] - 6s 8ms/step - loss: 0.6644 - binary_accuracy: 0.6867 - val_loss: 0.6147 - val_binary_accuracy: 0.7762\n","Epoch 2/10\n","625/625 [==============================] - 5s 8ms/step - loss: 0.5487 - binary_accuracy: 0.7999 - val_loss: 0.4984 - val_binary_accuracy: 0.8202\n","Epoch 3/10\n","625/625 [==============================] - 5s 8ms/step - loss: 0.4453 - binary_accuracy: 0.8436 - val_loss: 0.4206 - val_binary_accuracy: 0.8456\n","Epoch 4/10\n","625/625 [==============================] - 5s 8ms/step - loss: 0.3789 - binary_accuracy: 0.8640 - val_loss: 0.3743 - val_binary_accuracy: 0.8600\n","Epoch 5/10\n","625/625 [==============================] - 5s 8ms/step - loss: 0.3355 - binary_accuracy: 0.8791 - val_loss: 0.3456 - val_binary_accuracy: 0.8672\n","Epoch 6/10\n","625/625 [==============================] - 5s 8ms/step - loss: 0.3055 - binary_accuracy: 0.8895 - val_loss: 0.3264 - val_binary_accuracy: 0.8718\n","Epoch 7/10\n","625/625 [==============================] - 5s 8ms/step - loss: 0.2821 - binary_accuracy: 0.8980 - val_loss: 0.3128 - val_binary_accuracy: 0.8734\n","Epoch 8/10\n","625/625 [==============================] - 5s 8ms/step - loss: 0.2620 - binary_accuracy: 0.9049 - val_loss: 0.3034 - val_binary_accuracy: 0.8760\n","Epoch 9/10\n","625/625 [==============================] - 5s 8ms/step - loss: 0.2458 - binary_accuracy: 0.9100 - val_loss: 0.2967 - val_binary_accuracy: 0.8780\n","Epoch 10/10\n","625/625 [==============================] - 5s 8ms/step - loss: 0.2309 - binary_accuracy: 0.9152 - val_loss: 0.2920 - val_binary_accuracy: 0.8802\n"]}]},{"cell_type":"markdown","source":["5. Evaluate the Model"],"metadata":{"id":"rutEG69vwnXX"}},{"cell_type":"code","source":["### Let's see how the model performs. Two values will be returned. Loss (a number which represents our error, lower values are better), and accuracy.\n","\n","loss, accuracy = model.evaluate(test_ds)\n","\n","print(\"Loss: \", loss)\n","print(\"Accuracy: \", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z90AC46jwsYy","executionInfo":{"status":"ok","timestamp":1643147498912,"user_tz":360,"elapsed":2688,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"e04190c5-8afd-4506-ae08-579811a87477"},"execution_count":116,"outputs":[{"output_type":"stream","name":"stdout","text":["782/782 [==============================] - 2s 3ms/step - loss: 0.3098 - binary_accuracy: 0.8741\n","Loss:  0.30979806184768677\n","Accuracy:  0.8740800023078918\n"]}]},{"cell_type":"code","source":["### Create a graph of loss and accuracy. model.fit() returns a History object that contains a dictionary with everything that happened during training:\n","\n","history_dict = history.history\n","history_dict.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jxvtA63txKDB","executionInfo":{"status":"ok","timestamp":1643145452373,"user_tz":360,"elapsed":125,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"30ddf680-3b8e-4022-9282-4902020d589f"},"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['loss', 'binary_accuracy', 'val_loss', 'val_binary_accuracy'])"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["### There are four entries: one for each monitored metric during training and validation. You can use these to plot the training and validation loss for comparison,\n","### as well as the training and validation accuracy:\n","\n","acc = history_dict['binary_accuracy']\n","val_acc = history_dict['val_binary_accuracy']\n","loss = history_dict['loss']\n","val_loss = history_dict['val_loss']\n","\n","epochs = range(1, len(acc) + 1)\n","\n","# \"bo\" is for \"blue dot\"\n","plt.plot(epochs, loss, 'bo', label='Training loss')\n","# b is for \"solid blue line\"\n","plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"9lrV7t2Fxjxg","executionInfo":{"status":"ok","timestamp":1643145480425,"user_tz":360,"elapsed":438,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"e52c3113-938e-4798-8537-68272b45abdf"},"execution_count":60,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["plt.plot(epochs, acc, 'bo', label='Training acc')\n","plt.plot(epochs, val_acc, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend(loc='lower right')\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"af_ogSxGxvrX","executionInfo":{"status":"ok","timestamp":1643145493763,"user_tz":360,"elapsed":625,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"06a56118-3a62-439f-e37e-5ee54bead217"},"execution_count":61,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["### In this plot, the dots represent the training loss and accuracy, and the solid lines are the validation loss and accuracy. Notice the training loss decreases with each epoch and the\n","### training accuracy increases with each epoch. This is expected when using a gradient descent optimization—it should minimize the desired quantity on every iteration.\n","### This isn't the case for the validation loss and accuracy—they seem to peak before the training accuracy. This is an example of overfitting: the model performs better on the training\n","### data than it does on data it has never seen before. After this point, the model over-optimizes and learns representations specific to the training data that do not generalize to test data.\n","### For this particular case, you could prevent overfitting by simply stopping the training when the validation accuracy is no longer increasing. One way to do so is to use\n","### the tf.keras.callbacks.EarlyStopping callback."],"metadata":{"id":"vkGLZZRJyLSR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["6. Export the Model"],"metadata":{"id":"Jfr26DXvzoc_"}},{"cell_type":"code","source":["### In the code above, you applied the TextVectorization layer to the dataset before feeding text to the model. If you want to make your model capable of processing raw strings \n","### (for example, to simplify deploying it), you can include the TextVectorization layer inside your model. To do so, you can create a new model using the weights you just trained.\n","\n","export_model = tf.keras.Sequential([\n","  vectorize_layer,\n","  model,\n","  layers.Activation('sigmoid')\n","])\n","\n","export_model.compile(\n","    loss=losses.BinaryCrossentropy(from_logits=False), optimizer=\"adam\", metrics=['accuracy']\n",")\n"],"metadata":{"id":"eGlIQ19DzrOz","executionInfo":{"status":"ok","timestamp":1643145562082,"user_tz":360,"elapsed":110,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["### Test it with `raw_test_ds`, which yields raw strings\n","\n","loss, accuracy = export_model.evaluate(raw_test_ds)\n","print(accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kc_7e9Im0CBC","executionInfo":{"status":"ok","timestamp":1643145584152,"user_tz":360,"elapsed":9382,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"82aa2aad-8c19-482e-edbc-33e05db6ebeb"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["782/782 [==============================] - 9s 11ms/step - loss: 0.3099 - accuracy: 0.8739\n","0.8738800287246704\n"]}]},{"cell_type":"code","source":["### Inference on new data. To get predictions for new examples, you can simply call model.predict().\n","\n","examples = [\n","  \"The movie was great!\",\n","  \"The movie was okay.\",\n","  \"The movie was terrible...\"\n","]\n","\n","export_model.predict(examples)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UvLDj2-P0JNX","executionInfo":{"status":"ok","timestamp":1643145590904,"user_tz":360,"elapsed":273,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"d8bfc134-895c-439d-cdea-8d1109f42c58"},"execution_count":64,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.637708  ],\n","       [0.466421  ],\n","       [0.37946588]], dtype=float32)"]},"metadata":{},"execution_count":64}]}]}