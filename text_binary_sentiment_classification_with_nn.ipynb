{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"text_binary_sentiment_classification.ipynb","provenance":[{"file_id":"1KKzm7Fsb-JxkgcivIHtTqI080D4bcIjQ","timestamp":1637099402867}],"collapsed_sections":[],"mount_file_id":"1NKljkDS7tX3iuRXP2XsllgfAmElbvytG","authorship_tag":"ABX9TyNunORfU6Ahesw7zzUUrL02"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Introduction**"],"metadata":{"id":"FE8Jd_7qxAvy"}},{"cell_type":"markdown","source":["> This model demonstrates basic text classification starting from plain text files stored on disk. The model is trained to perform sentiment analysis on an IMDB dataset of movie reviews. This is an example of binary classification as it classifies movie reviews as either positive or negative."],"metadata":{"id":"NXkOq_cFDP6J"}},{"cell_type":"markdown","source":["\n","\n","> For this exercise, I'll use tensorflow 'layers' and 'losses' modules to build a neural network to classify movie reviews. The tensorflow layers.TextVectorization function will convert the input text to vectors, and, a simple neural network will generate probabilities for which sentiment applies to each text string. The neural network includes Embedding, Dropout, GlobalAveragePooling1D, and Dense layers. The 're' and 'string' modules will enable basic string operations, and the 'os' and 'shutil' modules support operating systrem and high-level file and directory handling. \n","\n"],"metadata":{"id":"c40SWiuFEaWj"}},{"cell_type":"markdown","metadata":{"id":"EUXbwXyWn0Sx"},"source":["**1. Setup**"]},{"cell_type":"code","metadata":{"id":"O2GoVE04uSCv"},"source":["import matplotlib.pyplot as plt\n","import os #(enables operating system dependent functionality)\n","import shutil #(for high-level file and directory handling)\n","import re #(this is the regular expression module)\n","import string #(for common string operations)\n","import tensorflow as tf #(tensorflow core v 2.7)\n","\n","from tensorflow.keras import layers #(takes ina tensor and outputs a tensor)\n","from tensorflow.keras import losses #(used to compute the crossentropy loss between actual and predicted values)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EwtrTzSevQd-","executionInfo":{"status":"ok","timestamp":1643755103787,"user_tz":360,"elapsed":109,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"935dc336-b0ab-487b-a49d-070b48ebcb27"},"source":["print(tf.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.7.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"RTzP6sakn5NR"},"source":["**2. Pre-process Data**"]},{"cell_type":"markdown","source":["  > **a) Download data from url**"],"metadata":{"id":"V5Nsr9RzbB8e"}},{"cell_type":"markdown","source":["\n","\n","> The Large Movie Review Dataset contains 50,000 movie reviews from the Internet Movie Database. These are split into 25,000 reviews for training and 25,000 reviews for testing. The training and testing sets are balanced, meaning they contain an equal number of positive and negative reviews.\n","\n"],"metadata":{"id":"IMkydonzD5A9"}},{"cell_type":"markdown","source":["\n","\n","> The \"tf.keras.utils.get_file\" method is used to download the dataset directly from the url. Default arguments per documkentation are tf.keras.utils.get_file (fname=None, origin=None, untar=False, md5_hash=None, file_hash=None, cache_subdir='datasets', hash_algorithm='auto', extract=False, archive_format='auto', cache_dir=None). The \"untar\" argument is a boolean, whether the file should be decompressed or not. In this case it needs to be decompressed because the source file ends in \".tar.gz\"."],"metadata":{"id":"HLMg3G6XGoFa"}},{"cell_type":"code","metadata":{"id":"KwsBcODn_PLI"},"source":["url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\" \n","dataset =  tf.keras.utils.get_file(\"aclImdb_v1\", url, untar=True, cache_dir='.', cache_subdir='')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["> **b) Identify directory and file structure**"],"metadata":{"id":"QhBcWe7GLgHJ"}},{"cell_type":"code","source":["os.path.dirname(dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"9HzX_OuYr84p","executionInfo":{"status":"ok","timestamp":1643755148850,"user_tz":360,"elapsed":104,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"9f569375-f64f-42e0-ea25-7d002a5ae3f3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'.'"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["os.listdir('./')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KGDXRLSXjcnV","executionInfo":{"status":"ok","timestamp":1643755150262,"user_tz":360,"elapsed":119,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"24b3f0f3-d1ca-4439-b542-5ec86c64daf7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['.config', 'aclImdb_v1.tar.gz', 'aclImdb', 'drive', 'sample_data']"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["os.listdir('./aclImdb/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jX2O2A0LtkYN","executionInfo":{"status":"ok","timestamp":1643755151489,"user_tz":360,"elapsed":107,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"0ec04c6c-bd3b-47ea-95f5-e11d5aec5eca"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['test', 'README', 'imdb.vocab', 'imdbEr.txt', 'train']"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["os.listdir('./aclImdb/train/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a8B5-phsEOKi","executionInfo":{"status":"ok","timestamp":1643755152633,"user_tz":360,"elapsed":114,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"3ea74036-425f-4117-c6f6-fdca8e1e98ce"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['urls_neg.txt',\n"," 'pos',\n"," 'urls_unsup.txt',\n"," 'urls_pos.txt',\n"," 'unsupBow.feat',\n"," 'labeledBow.feat',\n"," 'neg',\n"," 'unsup']"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["os.listdir('./aclImdb/test/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7F0Cq3rSLIeH","executionInfo":{"status":"ok","timestamp":1643755155414,"user_tz":360,"elapsed":136,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"95e612de-2acb-4b9a-fe95-c5c833814f91"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['urls_neg.txt', 'pos', 'urls_pos.txt', 'labeledBow.feat', 'neg']"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"1QrElBCx8swm"},"source":["> **c) Examine sample files**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vKKIEHgV50kv","executionInfo":{"status":"ok","timestamp":1643755158713,"user_tz":360,"elapsed":185,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"5564453d-207c-46f0-a5d3-555cd5b6a231"},"source":["os.listdir('./aclImdb/train/pos')[:5]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['2248_7.txt', '6990_8.txt', '10597_9.txt', '7204_8.txt', '11733_10.txt']"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jLQXIbKXAcXy","executionInfo":{"status":"ok","timestamp":1643755159895,"user_tz":360,"elapsed":116,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"b776a74c-71d3-494b-9f06-c708c578e8a6"},"source":["sample_file = os.path.join('./aclImdb/train/', 'pos/7204_8.txt')\n","with open(sample_file) as f:\n","  print(f.read())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["If you are looking for a sonic-boom-special-effects monster, click the BACK button on your browser.<br /><br />Deathtrap was written by Ira Levin (Sliver, The Stepford Wives, Rosemary's Baby). It's a stage play, adapted for the screen. 95% of the movie takes place in the gorgeous home of playwright Sidney Bruhl (Michael Caine). He's the author of a fabulously successful Broadway play, but his last 4 efforts have flopped - horribly.<br /><br />An aspiring playwright, Clifford Anderson (Christopher Reeve), who attended a play-writing workshop given by Sydney, has sent him a copy of the play he has written. Sydney tells his wife, Myra (Dyan Cannon) the play is fabulous - a sure-fire hit. But is it good enough to die for? Time will tell.<br /><br />Clever dialog and numerous twists and turns in the plot keep this movie entertaining from beginning to end. The whole cast seems to have a good time. It's reminiscent of another fun Michael Caine mystery: Sleuth. Worth watching.<br /><br />\n"]}]},{"cell_type":"code","source":["os.listdir('./aclImdb/test/pos')[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N3n-7hnPO6d5","executionInfo":{"status":"ok","timestamp":1643755161128,"user_tz":360,"elapsed":111,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"4bd9a2eb-b465-45af-ebf7-96b07d7698dc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['6990_8.txt', '11257_10.txt', '11733_10.txt', '4341_7.txt', '8705_10.txt']"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["sample_file2 = os.path.join('./aclImdb/test/', 'pos/4341_7.txt')\n","with open(sample_file2) as f:\n","    print(f.read())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M-yakYDJBSdb","executionInfo":{"status":"ok","timestamp":1643755162304,"user_tz":360,"elapsed":126,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"c438620a-044b-40a1-f7e6-f3ae14d336b1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LOL.<br /><br />The mere fact that I start off my review with 'lol' says it all. I used to watch this movie all the time as a kid; and even then I sensed the silliness of it all. The low budget, horrible acting and lame script was ever apparent back then. I watched it again yesterday and just couldn't stop laughing. It's so bad it's actually good lol. Like another reviewer said, it doesn't take itself seriously. There's no way one could look at this movie and say that the makers did so. The soundtrack is so funny, I laugh every time I hear it. The 'climax' is just a laugh riot. It's an all out war zone in New York, full of explosions and total chaos...so ridiculous you can't help but chuckle at the sight of it. <br /><br />Other hilarious moments: <br /><br />- The scene with Kersey and the cop running side by side like 2 cowboys against the whole Wild West was so cheesy it was funny.<br /><br />-It killed me how the bad guys could be shooting at Kersey and he could even drop down on one knee taking ever-so-careful (and slow) aim and not get hit LMAO. Of course, with him it was one shot-one kill with his elephant handgun LOL.<br /><br />- Another hilarious scene was the end when he finally killed the leader of the gang....with a ROCKET LAUNCHER lol...destroying the whole side of the apartment building with it.<br /><br />- It's apparent that Kersey is all but used to losing loved ones...when his new girlfriend is quickly disposed of after only a few dates. The acting is so bad that you can't blame anyone that could only think that Kersey is mad at the destruction of the car lol....he runs down, looks at the carnage and just walks away.<br /><br />Again, so bad, it's good.<br /><br />*** out of **** stars.\n"]}]},{"cell_type":"markdown","metadata":{"id":"j3kK8N85o1WD"},"source":["> **d) Establish training, validation & test data splits**"]},{"cell_type":"markdown","source":["\n","\n","> To prepare a dataset for binary classification, you will need two folders corresponding to class_a and class_b. These will be the positive and \n","negative movie reviews, which can be found in aclImdb/train/pos and aclImdb/train/neg. Since the dataset contains additional folders, it is best to remove them beforehand. "],"metadata":{"id":"twhgbip2SxDj"}},{"cell_type":"code","metadata":{"id":"RWpNefcCBwQ8"},"source":["shutil.rmtree('./aclImdb/train/unsup')"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.listdir('./aclImdb/train/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sXvcUFq3DYfM","executionInfo":{"status":"ok","timestamp":1643755180943,"user_tz":360,"elapsed":233,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"51845824-f93c-463e-a8b5-9196594a75af"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['urls_neg.txt',\n"," 'pos',\n"," 'urls_unsup.txt',\n"," 'urls_pos.txt',\n"," 'unsupBow.feat',\n"," 'labeledBow.feat',\n"," 'neg']"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["\n","\n","> The next step is to preparer the data for training. The tf.keras.text_dataset_from_directory utility is utilized. The default arguments are tf.keras.utils.text_dataset_from_directory(directory, labels='inferred', label_mode='int', class_names=None, batch_size=32, max_length=None, shuffle=True, seed=None, validation_split=None, subset=None, follow_links=False). Part of this process is splitting the training data into training and validation splits. An 80:20 split is used here. Note that batch_size and seed are declared variables outside of the function call. There is a total of 25,000\n","text files in the train folder. Some positive and some negative. The below command takes all 25,000 from both classes, pos and neg, shuffles them, reserves 20% for validation and returns the raw train dataset."],"metadata":{"id":"tR4h0j2uTjxZ"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ELpccsfxCLMy","executionInfo":{"status":"ok","timestamp":1643755188477,"user_tz":360,"elapsed":2077,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"c186b8eb-75f5-446f-e41d-e70863c2878a"},"source":["batch_size = 32\n","seed = 42\n","\n","raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n","    'aclImdb/train', \n","    batch_size=batch_size, \n","    validation_split=0.2, \n","    subset='training', \n","    seed=seed)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 25000 files belonging to 2 classes.\n","Using 20000 files for training.\n"]}]},{"cell_type":"code","source":["type(raw_train_ds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TJC9Mp2zVlKn","executionInfo":{"status":"ok","timestamp":1643755192214,"user_tz":360,"elapsed":120,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"60071d66-a41a-47ed-8815-0e474d192874"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensorflow.python.data.ops.dataset_ops.BatchDataset"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["\n","\n","> The tf.keras.utils.text_dataset_from_directory() method will return a tf.data.Dataset that yields batches of texts from the subdirectories class_a and class_b, together with labels 0 and 1 (0 corresponding to class_a and 1 corresponding to class_b). Only .txt files are supported at this time. Note, by default labels='inferred' and label_mode='int' in the method's parameters dictate this approach. It yields a tuple (texts, labels), where texts has shape (batch_size,) and labels follows the following format: if label_mode is int, the labels are an int32 tensor of shape (batch_size,). if label_mode is binary, the labels are a float32 tensor of 1s and 0s of shape (batch_size, 1). if label_mode is categorial, the labels are a float32 tensor of shape (batch_size, num_classes), representing a one-hot encoding of the class index. So in this case, the dataset is a tuple of text and labels (texts, labels)."],"metadata":{"id":"IHksQQi4WORn"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gwW48pElElgB","executionInfo":{"status":"ok","timestamp":1643755195230,"user_tz":360,"elapsed":185,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"6946f9b0-51b0-43b3-cdb7-bfd73dc3599f"},"source":["for text_batch, label_batch in raw_train_ds.take(1): # The reviews contain raw text with punctuation and HTML tags, plus \"b'\" before each review.\n","  for i in range(3):\n","    print(\"Review\", text_batch.numpy()[i])\n","    print(\"Label\", label_batch.numpy()[i])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Review b'\"Pandemonium\" is a horror movie spoof that comes off more stupid than funny. Believe me when I tell you, I love comedies. Especially comedy spoofs. \"Airplane\", \"The Naked Gun\" trilogy, \"Blazing Saddles\", \"High Anxiety\", and \"Spaceballs\" are some of my favorite comedies that spoof a particular genre. \"Pandemonium\" is not up there with those films. Most of the scenes in this movie had me sitting there in stunned silence because the movie wasn\\'t all that funny. There are a few laughs in the film, but when you watch a comedy, you expect to laugh a lot more than a few times and that\\'s all this film has going for it. Geez, \"Scream\" had more laughs than this film and that was more of a horror film. How bizarre is that?<br /><br />*1/2 (out of four)'\n","Label 0\n","Review b\"David Mamet is a very interesting and a very un-equal director. His first movie 'House of Games' was the one I liked best, and it set a series of films with characters whose perspective of life changes as they get into complicated situations, and so does the perspective of the viewer.<br /><br />So is 'Homicide' which from the title tries to set the mind of the viewer to the usual crime drama. The principal characters are two cops, one Jewish and one Irish who deal with a racially charged area. The murder of an old Jewish shop owner who proves to be an ancient veteran of the Israeli Independence war triggers the Jewish identity in the mind and heart of the Jewish detective.<br /><br />This is were the flaws of the film are the more obvious. The process of awakening is theatrical and hard to believe, the group of Jewish militants is operatic, and the way the detective eventually walks to the final violent confrontation is pathetic. The end of the film itself is Mamet-like smart, but disappoints from a human emotional perspective.<br /><br />Joe Mantegna and William Macy give strong performances, but the flaws of the story are too evident to be easily compensated.\"\n","Label 0\n","Review b'Great documentary about the lives of NY firefighters during the worst terrorist attack of all time.. That reason alone is why this should be a must see collectors item.. What shocked me was not only the attacks, but the\"High Fat Diet\" and physical appearance of some of these firefighters. I think a lot of Doctors would agree with me that,in the physical shape they were in, some of these firefighters would NOT of made it to the 79th floor carrying over 60 lbs of gear. Having said that i now have a greater respect for firefighters and i realize becoming a firefighter is a life altering job. The French have a history of making great documentary\\'s and that is what this is, a Great Documentary.....'\n","Label 1\n"]}]},{"cell_type":"markdown","source":["\n","\n","> Below we confirm the class names and associated integers. \"0\" means negative and \"1\" means positive.\n","\n"],"metadata":{"id":"onBSBqrMhY4v"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rHLpYCGgFQ9N","executionInfo":{"status":"ok","timestamp":1643755199238,"user_tz":360,"elapsed":159,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"bb2c7d04-7e11-4bd7-f4c5-76249aaf8dff"},"source":["### Notice the reviews contain raw text (with punctuation and occasional HTML tags like <br/>). You will see how to handle these in the following section.\n","### The labels are 0 or 1. To see which of these correspond to positive and negative movie reviews, you can check the 'class_names' property on the dataset.\n","\n","print(\"Label 0 corresponds to\", raw_train_ds.class_names[0])\n","print(\"Label 1 corresponds to\", raw_train_ds.class_names[1])\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Label 0 corresponds to neg\n","Label 1 corresponds to pos\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vmBbHvPopR5L","executionInfo":{"status":"ok","timestamp":1643755204468,"user_tz":360,"elapsed":1349,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"d4fc0e4c-b855-4004-9dde-f4ec495a06ab"},"source":["raw_val_ds = tf.keras.utils.text_dataset_from_directory(\n","    'aclImdb/train', \n","    batch_size=batch_size, \n","    validation_split=0.2, \n","    subset='validation', \n","    seed=seed)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 25000 files belonging to 2 classes.\n","Using 5000 files for validation.\n"]}]},{"cell_type":"code","source":["for text_batch, label_batch in raw_val_ds.take(1): # The reviews contain raw text with punctuation and HTML tags, plus \"b'\" before each review.\n","  for i in range(3):\n","    print(\"Review\", text_batch.numpy()[i])\n","    print(\"Label\", label_batch.numpy()[i])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lcbus29CiSA4","executionInfo":{"status":"ok","timestamp":1643755208495,"user_tz":360,"elapsed":283,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"1944f7bb-7ee6-4d58-d31f-9631e09733ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Review b'a friend gave it to me saying it was another classic like \"Debbie does Dallas\". Nowhere close. I think my main complaint is about the most unattractive lead actress in porn industry ever. Even more terrible is that she is on screen virtually all the time. But I read somewhere that back in those days, porn had to have some \"artistic\" value. I was unable to find it though. See it only if you are interested in history of development of porn into mainstream, or can appreciate art in porn movies. I know I am not. But the director of the movie appears to be a talented person. He even tried to get Simon & Garfunkel to give him permissions to use his songs. Of course, they rejected.'\n","Label 0\n","Review b\"The scenes are fast-paced. the characters are great. I love Anne-Marie Johnson's acting. I really like the ending. <br /><br />However, I was disappointed that this movie didn't delve deeper into Achilles's and Athena's relationship. It only blossomed when they kissed each other.\"\n","Label 1\n","Review b'Although i am inclined to agree with the other comments made by people who have seen this movie, i am ashamed to say i rather like it. Not often can such a huge pile of 80s pap be found outside of a Wham! video, so it is most definitely worth a viewing (\\xc2\\xa30.79 a night in my local store!). Watch out for the insanely obvious seams and zip on the monster\\'s costume, the fact that the \\'hero\\' looks a lot like Keith Chegwin and such classic lines as the following: Evil Wizard-Type Bloke: \"At last we meet Kor...\" Kor: \"Thrilling, isn\\'t it?\"<br /><br />Amazing!!I also like the fact that although the video box looks quite exciting with images of a castle surrounded by raging seas and a dangerous falcon-like bird carrying a handsome hero to safety (among other such \\'interesting and engaging\\' suggestions of what goes on in the actual film, none of them actually happen. No, I\\'m not joking...there really isn\\'t a raging sea or a ferocious bird, it\\'s just trying to make you interested...classic in my opinion. This film gets 10 for pure entertainment value!!'\n","Label 1\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"199_c9TRp61f","executionInfo":{"status":"ok","timestamp":1643755212632,"user_tz":360,"elapsed":1598,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"53429a7e-0145-43ce-9cc6-80577f590093"},"source":["raw_test_ds = tf.keras.utils.text_dataset_from_directory(\n","    'aclImdb/test', \n","    batch_size=batch_size)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 25000 files belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["for text_batch, label_batch in raw_test_ds.take(1): # The reviews contain raw text with punctuation and HTML tags, plus \"b'\" before each review.\n","  for i in range(3):\n","    print(\"Review\", text_batch.numpy()[i])\n","    print(\"Label\", label_batch.numpy()[i])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zyAilRL8iZtR","executionInfo":{"status":"ok","timestamp":1643755214801,"user_tz":360,"elapsed":256,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"aec858ec-d1c5-4972-953c-250f58f1cad1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Review b'I only rented this stinker because of its relatively high ratings. It totally sucked! I cannot imagine how anyone would think this a good movie - even an OK movie. None of the characters had ANY redeeming qualities of any kind. To varying degrees they were each selfish and mean-spirited - or abused and damaged personalities who hadn\\'t a clue about the spirit of Christmas (when this takes place!) I know Canadians and like them - but I cannot think that even THEY would think this a good movie. I\\'d rather a sharp stick in the eye than watch this offensive movie again. A colossal waste of time and money. Do not believe the person who wrote the opinion that it was \"worth watching.\" This person probably would enjoy having a dentist drill their teeth without anesthesia, too. Don\\'t mean to be unkind but for the life of me I cannot imagine what this person was thinking. Unless they had ulterior motives. Maybe s/he was the director or the producer. If so, I\\'d like to ask them to give me back my money. If your money is important to you - save it instead of renting this piece of drek - or rent something (anything!) else. I\\'m running out of good reasons NOT TO rent this film. If I were Canadian I\\'d be ASHAMED that it\\'s supposed to be a favorite Canadian flick. If so, I would say that those who think so are definitely in need of great quantities of powerful drugs. YECK!'\n","Label 0\n","Review b'Earnest effort which achieves some success to adapt the classic Odyssey story to a \\'30\\'s nostalgia period piece. The adventurers this time are escaped convicts, wandering about the Depression afflicted South bungling their way into trouble.<br /><br />The greatest strength of the film is the wonderful music soundtrack, effectively evoking not only the era that this is set in, but the spiritual references that run rampant in the film. Besides its value to the tone of the movie, the music is just plain fun to listen to.<br /><br />What cripples the film is that the characters really aren\\'t that likable. In a comedy, you need that element in order to have fun along with them in their misadventures. Instead, we have a bunch of selfish, arrogant, soulless, mean spirited nobodies who really have no positive points at all. They\\'re not imposing enough to make you hate them either, so it\\'s hard to relate to them at all. They\\'re offered up as clowns, but like people who put clown makeup on and march in parades, they just aren\\'t funny.<br /><br />Like the story that inspired it, the movie takes these guys on an \"odyssey,\" encountering a variety of symbolic (some even mystical) characters. Everybody is stamped with offensive stereotypes, the operative word being \"stupid.\" People are mocked right and left, and consequently, no one is left being particularly interesting or appealing. The movie doesn\\'t like its own characters, and it doesn\\'t let you like them, either.<br /><br />Riverside baptisms, beautiful sirens, stolen cars, fistfights, radio preachers, people being whipped with sticks; all are thrown at you in disjointed fashion. Some evoke a few laughs, others confuse or bore you. I did laugh when a nerdy guy beat the snot out of an especially obnoxious lead character. But there were a lot more pointlessly gratuitous scenes; an example: some \\'30\\'s Dillinger-type guy strafes cows with a tommy-gun. Comedy? Symbolism? No; just mindless violence, which detracts from the intellectual nature of the original source material this story draws upon.<br /><br />Other adaptations of the Odyssey are much better. Unless you\\'re a George Clooney fan, rent something else. But buy the soundtrack CD; the music is great.'\n","Label 0\n","Review b\"Hellboy revolves around classic comic book/action/superhero genre story lines. Essentially Hellboy is a kind of demon who has found his way on earth. He is brought up from a child by a priest and within a government society and has chosen to protect the people of earth from the supernatural, rather then be a menace (the normal career route for a demon).<br /><br />The set up of the story involves creative uses of history, combining Nazi experiments with the occult. It's preposterous, but so is the whole idea of a demon roaming the streets. I find the explanations of the characters, who they are and how they came to be very well handled. The sequences are to the point and very entertaining. In fact the opening is the best part of the film, therein lays the problem\\xc2\\x85.<br /><br />Essentially Del Toro who both writes and directs this piece bottles it. The film is absent of all tension or any major conflict. Hellboy is essentially established as invincible within the first act and so the rest of the film comprises of scenes in which any conflict is automatically rather crass because we know inevitably Hellboy will be OK and the bad guy will die. I hear you cry that this is the case for any action/hero film. Well yes it is, but once we are drawn into a well made action film we can't help but feel the hero may die. Die Hard works because John Mclane looks likely to die at all parts. He escapes death by the slimmest of margins. The stakes are raised as his wife is also in danger etc etc\\xc2\\x85 Terminator and Terminator two work because in both cases the villain is far superior than the hero. The threat and tension is constant.<br /><br />Some of the other major weaknesses are: Del Toro is also guilty of employing deus ex machina. Characters generally disappear and reappear as their skills are needed within the story. The villain is featured in maybe three scenes. He has no motives. Turns up unexpectedly and inexplicably. In the one scene Hellboy looks to be up against a real threat (groups of monsters) a character unleashes her abilities - the screen fades to white and inexplicably the monsters are dead but everybody else lives. A minor character established in an irritating and undeveloped love story becomes the key to the conclusion of the film. Her character is so thin, the relationship so undeveloped. It is clear she is nothing more than a prop of sorts to push the plot along and to make it all make sense. I don't want to ruin the ending of the film but essentially a character that is dead is miraculously and unbelievably brought back to life\\xc2\\x85.<br /><br />The film suffers from poor dialogue and one liners that just aren't smart or funny. After a while it all starts to grate.<br /><br />What's more Del Toro blows the action scenes with some uninspired visuals. And whoever made the creative decision to make hellboy's primary weapon a gun instead of his clunking arm should be fired. Essentially the use of the gun weakens the concept of the film, degrading the fights to nothing more than a one sided shoot out <br /><br />The few positives include: The cinematography is very good. At all times a sense of mood is established by the dark lighting and the darker colour palette. As well as the use of interesting locations. Yet perhaps it is all a bit samey as well.<br /><br />The use of cgi and Fx is well done. Never do we get an over load. When effects are used they are used well and the sense of realism is kept. Rather similar to how Nolan used FX in batman. I much prefer this method to the overtop effects we often see.<br /><br />All in all this is a pretty poor film. The real shame is that (despite not reading the comics) I found the film wasted a lot of potential. Hellboy as a character has a lot of instantly apparent fascinating dimensions which are completely unexplored. The film has watch-ability, in the sense that if it comes on TV and nothing else is on it might be worth a viewing. But in any other situation I wouldn't bother with it.\"\n","Label 0\n"]}]},{"cell_type":"markdown","metadata":{"id":"5ipJxWNWE8CT"},"source":["> **e) Standardize, tokenize, and vectorize data for training**"]},{"cell_type":"markdown","source":["\n","\n","> The tf.keras tf.keras.layers.TextVectorization layer method is used to standardize, tokenize, and vectorize the data before modeling. Standardization includes removing punctuation and/or HTML elements, for example, to simplify the dataset. Tokenization splits strings into tokens (for example, splitting a sentence into individual words by splitting on whitespace). Vectorization refers to converting tokens into numbers/arrays so they can be fed into a neural network. The default arguments are tf.keras.layers.TextVectorization(max_tokens=None, standardize='lower_and_strip_punctuation', split='whitespace', ngrams=None, output_mode='int', output_sequence_length=None, pad_to_max_tokens=False, vocabulary=None, idf_weights=None, sparse=False, ragged=False, **kwargs)."],"metadata":{"id":"hcCzeiBpj1CQ"}},{"cell_type":"markdown","source":["\n","\n","> Note: To prevent training-testing skew it is important to preprocess the data identically at train and test time. If this is a concern, the TextVectorization layer can be included directly inside the model."],"metadata":{"id":"dWpHUhVmlZNG"}},{"cell_type":"markdown","source":["\n","\n","> The TextVectorization layer which converts text to lowercase and strips punctuation by default, doesn't strip HTML characters. A custom standardization function is needed to do that. It includes making all text lowercase and pulling out some HTML code breaks ie ',br />'. regex_replace() just substitutes one value for another. string.punctuation = !\"#$%&'()*+, -./:;<=>?@[\\]^_`{|}~. italicized text \n","\n"],"metadata":{"id":"2bJEoYM9lxEq"}},{"cell_type":"code","metadata":{"id":"2KKSU6JVFDoZ"},"source":["def custom_standardization(input_data):\n","  lowercase = tf.strings.lower(input_data)\n","  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n","  return tf.strings.regex_replace(stripped_html,\n","                                  '[%s]' % re.escape(string.punctuation),\n","                                  '')"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_sentence = \"This is a tests... % s to see %s how the commands *&^%$#@! work with 34% ?\"\n","test1 = tf.strings.regex_replace(test_sentence, 'see', 'seedoo')\n","test2 = tf.strings.regex_replace(test_sentence, '[%s]' % re.escape(string.punctuation), '')\n","print(test1)\n","print(test2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KSFDvTSHMopU","executionInfo":{"status":"ok","timestamp":1643755221994,"user_tz":360,"elapsed":115,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"d9e3c7f9-3074-4b7f-b689-30a0b4bdb38a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(b'This is a tests... % s to seedoo %s how the commands *&^%$#@! work with 34% ?', shape=(), dtype=string)\n","tf.Tensor(b'This is a tests  s to see s how the commands  work with 34 ', shape=(), dtype=string)\n"]}]},{"cell_type":"markdown","source":["\n","\n","> To create a all-encompassing text vectorization function, the TextVectorization layer is now used. This will standardize, tokenize, and vectorize our data. This will utilize the the custom standardization function you defined above. max_features and sequence_length are established here as global variables. Note that all sequences will now be 250 or less in length."],"metadata":{"id":"1nCLWyY1n7Bd"}},{"cell_type":"code","metadata":{"id":"wnXqXQjC3LvD"},"source":["max_features = 10000\n","sequence_length = 250\n","\n","vectorize_layer = layers.TextVectorization(\n","    standardize=custom_standardization,\n","    max_tokens=max_features,\n","    output_mode='int',\n","    output_sequence_length=sequence_length)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tJWgltzz-UAt","executionInfo":{"status":"ok","timestamp":1643755234017,"user_tz":360,"elapsed":106,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"744f50d6-d919-4853-d57e-c56227c6d2ad"},"source":["type(vectorize_layer)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["keras.layers.preprocessing.text_vectorization.TextVectorization"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["\n","\n","> Next, the adapt method is called to fit the state of the preprocessing layer to the dataset. Some preprocessing layers have an internal state that can be computed based on a sample of the training data. The list of stateful preprocessing layers is: 1) TextVectorization - holds a mapping between string tokens and integer indices; 2) StringLookup and IntegerLookup - holds a mapping between input values and integer indices; 3) Normalization - holds the mean and standard deviation of the features; and 4) Discretization - holds information about value bucket boundaries. These layers are non-trainable. Their state is not set during training. It must be set before training, either by initializing them from a precomputed constant, or by \"adapting\" them on data. You set the state of a preprocessing layer by exposing it to training data, via the adapt() method as shown here. Below the map function is used to remove the labels before utilizing the adapt function."],"metadata":{"id":"eEOiMyrZrWmF"}},{"cell_type":"code","metadata":{"id":"16JAvT5E4y_Z"},"source":["train_text = raw_train_ds.map(lambda x, y: x)\n","vectorize_layer.adapt(train_text)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","> The below 'vectorize_text' function will allow us to see the result of the TextVectorization layer in action."],"metadata":{"id":"1zEjBMLqpxdz"}},{"cell_type":"code","metadata":{"id":"gtiNUTqC-dza"},"source":["def vectorize_text(text, label):\n","  text = tf.expand_dims(text, -1)\n","  return vectorize_layer(text), label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fL0FrmT2-8rh","executionInfo":{"status":"ok","timestamp":1643755254765,"user_tz":360,"elapsed":151,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"9679a112-3e4b-45b9-c1d8-3d202fee3a2a"},"source":["text_batch, label_batch = next(iter(raw_train_ds))\n","first_review, first_label = text_batch[0], label_batch[0]\n","print(\"Review\", first_review)\n","print(\"Label\", raw_train_ds.class_names[first_label])\n","print(\"Vectorized review\", vectorize_text(first_review, first_label))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Review tf.Tensor(b'Great movie - especially the music - Etta James - \"At Last\". This speaks volumes when you have finally found that special someone.', shape=(), dtype=string)\n","Label neg\n","Vectorized review (<tf.Tensor: shape=(1, 250), dtype=int64, numpy=\n","array([[  86,   17,  260,    2,  222,    1,  571,   31,  229,   11, 2418,\n","           1,   51,   22,   25,  404,  251,   12,  306,  282,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0]])>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n"]}]},{"cell_type":"markdown","source":["\n","\n","> The array shape for the vectorized tex is (1, 250). 250 is the mex sequence length established earlier. Note: the last three numbers are zeros, which indicates they are padding. Also, each number in the array correspnds to a word. You can lookup the token (string or word) that each integer corresponds to by calling .get_vocabulary() on the layer. The vocabulary size corresponds to the maximum number of features set earlier (10,000)."],"metadata":{"id":"XZ3w2oVvtS88"}},{"cell_type":"code","source":["print(\"1287 ---> \",vectorize_layer.get_vocabulary()[1287])\n","print(\" 313 ---> \",vectorize_layer.get_vocabulary()[313])\n","print('Vocabulary size: {}'.format(len(vectorize_layer.get_vocabulary())))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FWy8jPCPIddn","executionInfo":{"status":"ok","timestamp":1643755258182,"user_tz":360,"elapsed":237,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"41e7d6e6-194c-44b2-dc04-aeb489eb3257"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1287 --->  silent\n"," 313 --->  night\n","Vocabulary size: 10000\n"]}]},{"cell_type":"markdown","source":["\n","\n","> To apply the vectorize_text function to the raw training data, as well as the test data, the .map function is used."],"metadata":{"id":"w46CDOJGutTC"}},{"cell_type":"code","source":["train_ds = raw_train_ds.map(vectorize_text)\n","val_ds = raw_val_ds.map(vectorize_text)\n","test_ds = raw_test_ds.map(vectorize_text)"],"metadata":{"id":"dz8BMM_TIwfZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(train_ds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ifBnydvgNavI","executionInfo":{"status":"ok","timestamp":1643755261208,"user_tz":360,"elapsed":105,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"a2ea5229-4df6-4b3b-80ae-5d879eb56ef0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensorflow.python.data.ops.dataset_ops.MapDataset"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","source":["\n","\n","> To view an item in thess objects, using an iterator is a good approach. Each iteration, as shown, is a 32x250 numpy array. 32 is the batch size. 250 is the maximum sequence length or the maximum length of a review allowed."],"metadata":{"id":"BHMrxYX2vEmd"}},{"cell_type":"code","source":["iterator = train_ds.__iter__()\n","next = iterator.get_next()\n","example = next[0]\n","print(example.numpy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZoxapgJ9Nf7X","executionInfo":{"status":"ok","timestamp":1643755264432,"user_tz":360,"elapsed":161,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"a92ff90a-6a63-4bc1-cc96-1772945ac9f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[   1    7    4 ...    0    0    0]\n"," [1354    2   61 ...    0    0    0]\n"," [  53  147    9 ...    0    0    0]\n"," ...\n"," [   2  435    5 ...    0    0    0]\n"," [   2 3137   65 ...    0    0    0]\n"," [1518 5282 1659 ...    0    0    0]]\n"]}]},{"cell_type":"code","source":["example.numpy().shape\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TRbENqqZTL0o","executionInfo":{"status":"ok","timestamp":1643755265876,"user_tz":360,"elapsed":108,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"6c7b53f5-99cd-4343-fc22-2e4ea30c9eba"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(32, 250)"]},"metadata":{},"execution_count":34}]},{"cell_type":"markdown","source":["> **f) Configure the dataset for performance**"],"metadata":{"id":"LP7uBMMSm0Mj"}},{"cell_type":"markdown","source":["> To make sure that I/O does not end up blocking when loading data and to maximize performance, use .cache() and .prefectch(). .cache() keeps data in memory after it's loaded off disk. This will ensure the dataset does not become a bottleneck while training your model. If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache, which is more efficient to read than many small files. .prefetch() overlaps data preprocessing and model execution while training. AUTOTUNE tunes the buffer value dynamically and is set here as a global variable."],"metadata":{"id":"Gr_C3PhuxpHT"}},{"cell_type":"code","source":["AUTOTUNE = tf.data.AUTOTUNE\n","\n","train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"],"metadata":{"id":"ZnayvtK5m82i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**3. Create the Model**"],"metadata":{"id":"VCpkk9LdUbLm"}},{"cell_type":"markdown","source":["> The model is a simple neural network made up of one Embedding layer, one GlobalAveragePooling1D layer, two dropout layers and 1 Dense layer. The Embedding layer can be understood as a lookup table that maps from integer indices (which stand for specific words) to dense vectors (their embeddings).\n","The default arguments are tf.keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None, kwargs). The GlobalAveragePooling1D layer returns a fixed-length output vector for each example by averaging over the sequence dimension. The output has one dimension in this case. This allows the model to handle input of variable length, in the simplest way possible. The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting. Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over all inputs is unchanged. Note that the Dropout layer only applies when training is set to True such that no values are dropped during inference. The default arguments are tf.keras.layers.Dropout(rate, noise_shape=None, seed=None, kwargs). Dense implements the operation: output = activation(dot(input, kernel) + bias) where activation is the element-wise activation function passed as the activation argument, kernel is a weights matrix created by the layer, and bias is a bias vector created by the layer (only applicable if use_bias is True)."],"metadata":{"id":"yykal_YqDmJo"}},{"cell_type":"code","source":["embedding_dim = 16 # this creates a global variable for the embedding dimension"],"metadata":{"id":"p_73FYj1UnfY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = tf.keras.Sequential([\n","  layers.Embedding(max_features + 1, embedding_dim),   # (32,250,16)\n","  layers.Dropout(0.2),                                 # (32,250,16)  \n","  layers.GlobalAveragePooling1D(),                     # (32, 16)\n","  layers.Dropout(0.2),                                 # (32, 16)\n","  layers.Dense(1)])                                    # (32,1)"],"metadata":{"id":"cxQezSEJVEJB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"nMSQiu1tVOMZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643755275137,"user_tz":360,"elapsed":124,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"b1720022-2bad-4da1-e765-a16ef547119c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, None, 16)          160016    \n","                                                                 \n"," dropout (Dropout)           (None, None, 16)          0         \n","                                                                 \n"," global_average_pooling1d (G  (None, 16)               0         \n"," lobalAveragePooling1D)                                          \n","                                                                 \n"," dropout_1 (Dropout)         (None, 16)                0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 17        \n","                                                                 \n","=================================================================\n","Total params: 160,033\n","Trainable params: 160,033\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["**4. Compile Model**"],"metadata":{"id":"OLqfue0dKAIa"}},{"cell_type":"markdown","source":["> Once the model is created, you can config the model with losses, an optimizer and metrics model.compile(). The default arguments are model.compile(optimizer='rmsprop', loss=None, metrics=None, loss_weights=None, weighted_metrics=None, run_eagerly=None, steps_per_execution=None, **kwargs). It is necessary to name a loss function and an optimizer for training. We want the model to output a probability (a single-unit layer with a sigmoid activation). The losses.BinaryCrossentropy loss function is appropriate for this. The default arguments are tf.keras.losses.BinaryCrossentropy(from_logits=False, label_smoothing=0.0, axis=-1, reduction=losses_utils.ReductionV2.AUTO, name='binary_crossentropy'). The optimizer chosen here is 'adam'. For metrics, we use the tf.metrics.BinaryAccuracy method. The default arguments are tf.keras.metrics.BinaryAccuracy(name='binary_accuracy', dtype=None, threshold=0.5)."],"metadata":{"id":"RGy2N-KsG26J"}},{"cell_type":"code","source":["model.compile(loss=losses.BinaryCrossentropy(from_logits=True),\n","              optimizer='adam',\n","              metrics=tf.metrics.BinaryAccuracy(threshold=0.0))"],"metadata":{"id":"kYfdKDmxsKFm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**5. Train the Model**"],"metadata":{"id":"61U_hPcQvNtw"}},{"cell_type":"markdown","source":[">  Train the model with tf.keras.model.fit(). To do so you will passing the dataset object to the fit method. Here we can also name the validation dataset and set the number of training epochs."],"metadata":{"id":"D8RqTwkPIifY"}},{"cell_type":"code","source":["epochs = 10\n","history = model.fit(\n","    train_ds,\n","    validation_data=val_ds,\n","    epochs=epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HAQwhPWIvish","executionInfo":{"status":"ok","timestamp":1643755353969,"user_tz":360,"elapsed":70307,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"ebf8937c-bd3e-400d-fdb2-afa63c59a7e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","625/625 [==============================] - 13s 20ms/step - loss: 0.6653 - binary_accuracy: 0.6901 - val_loss: 0.6175 - val_binary_accuracy: 0.7746\n","Epoch 2/10\n","625/625 [==============================] - 5s 8ms/step - loss: 0.5517 - binary_accuracy: 0.8000 - val_loss: 0.5010 - val_binary_accuracy: 0.8206\n","Epoch 3/10\n","625/625 [==============================] - 5s 8ms/step - loss: 0.4471 - binary_accuracy: 0.8423 - val_loss: 0.4220 - val_binary_accuracy: 0.8458\n","Epoch 4/10\n","625/625 [==============================] - 5s 8ms/step - loss: 0.3794 - binary_accuracy: 0.8647 - val_loss: 0.3750 - val_binary_accuracy: 0.8604\n","Epoch 5/10\n","625/625 [==============================] - 5s 8ms/step - loss: 0.3372 - binary_accuracy: 0.8791 - val_loss: 0.3462 - val_binary_accuracy: 0.8672\n","Epoch 6/10\n","625/625 [==============================] - 5s 8ms/step - loss: 0.3063 - binary_accuracy: 0.8874 - val_loss: 0.3270 - val_binary_accuracy: 0.8720\n","Epoch 7/10\n","625/625 [==============================] - 5s 8ms/step - loss: 0.2826 - binary_accuracy: 0.8956 - val_loss: 0.3136 - val_binary_accuracy: 0.8724\n","Epoch 8/10\n","625/625 [==============================] - 6s 10ms/step - loss: 0.2633 - binary_accuracy: 0.9033 - val_loss: 0.3041 - val_binary_accuracy: 0.8758\n","Epoch 9/10\n","625/625 [==============================] - 5s 9ms/step - loss: 0.2461 - binary_accuracy: 0.9106 - val_loss: 0.2977 - val_binary_accuracy: 0.8786\n","Epoch 10/10\n","625/625 [==============================] - 5s 8ms/step - loss: 0.2320 - binary_accuracy: 0.9156 - val_loss: 0.2929 - val_binary_accuracy: 0.8794\n"]}]},{"cell_type":"markdown","source":["**6. Evaluate the Model**"],"metadata":{"id":"rutEG69vwnXX"}},{"cell_type":"markdown","source":["> model.evaluate() can be used to assess model performance on the test dataset. The default arguments are model.evaluate(x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, return_dict=False, **kwargs). Two values will be returned: Loss (which represents the magnitude of error) and accuracy (a percentage)."],"metadata":{"id":"MInEWCIYLrX2"}},{"cell_type":"code","source":["loss, accuracy = model.evaluate(test_ds)\n","\n","print(\"Loss: \", loss)\n","print(\"Accuracy: \", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z90AC46jwsYy","executionInfo":{"status":"ok","timestamp":1643755370488,"user_tz":360,"elapsed":9421,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"cc16dd9c-382c-4aff-b13d-58ea32f7f88b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["782/782 [==============================] - 9s 12ms/step - loss: 0.3100 - binary_accuracy: 0.8737\n","Loss:  0.3100051283836365\n","Accuracy:  0.8737199902534485\n"]}]},{"cell_type":"markdown","source":["> model.fit() returns a History object that contains a dictionary with everything that happened during training. We can use this data to create a graph of loss and accuracy. There are four entries: one for each monitored metric during training and validation."],"metadata":{"id":"G_b6MRBaXRuD"}},{"cell_type":"code","source":["history_dict = history.history\n","history_dict.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jxvtA63txKDB","executionInfo":{"status":"ok","timestamp":1643755373953,"user_tz":360,"elapsed":141,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"b589d278-09a5-4b8d-d2b4-150cc8600b79"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['loss', 'binary_accuracy', 'val_loss', 'val_binary_accuracy'])"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["acc = history_dict['binary_accuracy']\n","val_acc = history_dict['val_binary_accuracy']\n","loss = history_dict['loss']\n","val_loss = history_dict['val_loss']\n","\n","epochs = range(1, len(acc) + 1)\n","\n","plt.plot(epochs, loss, 'bo', label='Training loss') # \"bo\" is for \"blue dot\"\n","plt.plot(epochs, val_loss, 'b', label='Validation loss') # b is for \"solid blue line\"\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"9lrV7t2Fxjxg","executionInfo":{"status":"ok","timestamp":1643755376502,"user_tz":360,"elapsed":337,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"186f0564-480a-46c8-ae8d-9fa32994078c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["plt.plot(epochs, acc, 'bo', label='Training acc')\n","plt.plot(epochs, val_acc, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend(loc='lower right')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"af_ogSxGxvrX","executionInfo":{"status":"ok","timestamp":1643755380512,"user_tz":360,"elapsed":357,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"d158afc3-3404-4be4-af1b-b34d9fe416d6"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["**7. Export the Model**"],"metadata":{"id":"Jfr26DXvzoc_"}},{"cell_type":"markdown","source":["> In the code above, the TextVectorization layer was applied to the dataset before feeding text to the model. To make the model capable of processing raw strings (for example, to simplify deploying it), add the TextVectorization layer to your model. To do so, it is easiest to use the weights that were just trained."],"metadata":{"id":"TtqxldQ6ZKDY"}},{"cell_type":"code","source":["export_model = tf.keras.Sequential([\n","  vectorize_layer,\n","  model,\n","  layers.Activation('sigmoid')\n","])\n","\n","export_model.compile(\n","    loss=losses.BinaryCrossentropy(from_logits=False), optimizer=\"adam\", metrics=['accuracy']\n",")\n"],"metadata":{"id":"eGlIQ19DzrOz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["> Below the exported model is tested on raw strings from the dataset."],"metadata":{"id":"gzO02-nuaEdS"}},{"cell_type":"code","source":["loss, accuracy = export_model.evaluate(raw_test_ds)\n","print(accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kc_7e9Im0CBC","executionInfo":{"status":"ok","timestamp":1643755399868,"user_tz":360,"elapsed":10667,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"2cb6bcf0-6d07-491e-f098-a75cf2f05ffd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["782/782 [==============================] - 10s 12ms/step - loss: 0.3100 - accuracy: 0.8737\n","0.8737199902534485\n"]}]},{"cell_type":"markdown","source":["> Inference on new data. To get predictions for new examples, call model.predict() on the new text. The default arguments for model.predict() are model.predict(x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)"],"metadata":{"id":"_pj8QSlkaZEB"}},{"cell_type":"code","source":["examples = [\n","  \"The movie was great!\",\n","  \"The movie was okay.\",\n","  \"The movie was terrible...\"\n","]\n","\n","export_model.predict(examples)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UvLDj2-P0JNX","executionInfo":{"status":"ok","timestamp":1643755404786,"user_tz":360,"elapsed":358,"user":{"displayName":"Chris Alexander","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12988381163962899800"}},"outputId":"96e89815-eb44-4345-84b8-ee5faf838795"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.63984054],\n","       [0.46747077],\n","       [0.382709  ]], dtype=float32)"]},"metadata":{},"execution_count":47}]},{"cell_type":"markdown","source":["> The predictions are probabilities. Rounding 0.5 and higher up to 1, or less than 0.5 down to 0 yields the appropriate labels. This suggests the first review is positive (rounds to 1) and the next two are negative (rounds to zero)."],"metadata":{"id":"YMlIJf9BbICV"}},{"cell_type":"markdown","source":["**8. Final Comments**"],"metadata":{"id":"bVQfsaVyeKnc"}},{"cell_type":"markdown","source":["\n","\n","> The model classified movie reviews with 87% accuracy after 10 epochs of training. Adding additional layers from the list of those already being used didn't improve performance. Instead it led to overfitting of the training data. This is an example where a simple model is quite powerrful without enhancement.\n","\n"],"metadata":{"id":"8h5a_lGZeSyD"}}]}
